{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Advanced Computer Vision Training .ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jE7Rj815AXks",
        "3eFpPIeZAabY",
        "N49NrPlcAddg",
        "hoC6dbd2bRKA",
        "jPXFAwUl1b5V",
        "WgQGI9_41fSJ",
        "uY6tbfDe1j3k",
        "oD3qK9B4liVT",
        "jEpIw2V0lmGF",
        "TO3WCmo2nB-Q",
        "3H1vHLHUmUId",
        "vNCS7L2amtYn",
        "av71E0Qcnwon",
        "lkEPDE4CrSsf",
        "FAALUD0-rmfJ",
        "SbWPTnTarthk",
        "itVuzyJZrzVR",
        "D6mpaNGixeDu",
        "YRck3uIwyeLo",
        "6naCWJHxygNk",
        "u4eKE0nEyxfk",
        "kMaVg1zTKCIG",
        "pa5s4rd3IpNy",
        "LUAaCFgMI1BF",
        "BR_NW9NRI3-t",
        "1sH7Cj5WKqoI",
        "3KA37_sbJHx2",
        "QrlPLfRA65Td",
        "TpKv4VWeZWuR",
        "lA4waja1-oM5",
        "_JS9mnQOAyID",
        "njdRT2vKMXjl",
        "G_aEYm4PVptX",
        "AliO7-3ZVY0R",
        "LbBe5fqIVcdS",
        "TRJT2KYRVlyB",
        "oftG5ka_YMyS",
        "CEmqPrAWa75W",
        "6tZ-97-pcFIW",
        "dm-q7PEUcqbM",
        "RTcnxwuMdWST",
        "5K0jWGjHQCk4",
        "FhDR8jvnS1Fl",
        "Xt8tuJzrOCUK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I47TcT30ufUp",
        "colab_type": "text"
      },
      "source": [
        "# Advanced Computer Vision Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyEOuO2oByJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr7i2L08IIp5",
        "colab_type": "text"
      },
      "source": [
        "# Topic 1 Image Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_VWhk9MJNbc",
        "colab_type": "text"
      },
      "source": [
        "## Teachable Machine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xwq-5tV_p77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lL5PUOB_uOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls '/content/drive/My Drive/dataset/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcvZN4P0-3pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "# Disable scientific notation for clarity\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Load the model\n",
        "model = tensorflow.keras.models.load_model('/content/drive/My Drive/dataset/keras_model.h5')\n",
        "\n",
        "# Create the array of the right shape to feed into the keras model\n",
        "# The 'length' or number of images you can put into the array is\n",
        "# determined by the first position in the shape tuple, in this case 1.\n",
        "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
        "\n",
        "# Replace this with the path to your image\n",
        "image = Image.open('/content/drive/My Drive/dataset/test_photo.jpg')\n",
        "\n",
        "#resize the image to a 224x224 with the same strategy as in TM2:\n",
        "#resizing the image to be at least 224x224 and then cropping from the center\n",
        "size = (224, 224)\n",
        "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
        "\n",
        "#turn the image into a numpy array\n",
        "image_array = np.asarray(image)\n",
        "\n",
        "# display the resized image\n",
        "image.show()\n",
        "\n",
        "# Normalize the image\n",
        "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
        "\n",
        "# Load the image into the array\n",
        "data[0] = normalized_image_array\n",
        "\n",
        "# run the inference\n",
        "prediction = model.predict(data)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2p2W2CEo240",
        "colab_type": "text"
      },
      "source": [
        "## Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GVgi54-2gk2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3qK9B4liVT",
        "colab_type": "text"
      },
      "source": [
        "### Import the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i02EGsya2lEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HtDXZUW2tpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50UcL1Cw2tlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWW-TrLWHUXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_cats_dir)\n",
        "print(train_dogs_dir)\n",
        "print(validation_cats_dir)\n",
        "print(validation_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwsapX6j22ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQqwvi4270h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEpIw2V0lmGF",
        "colab_type": "text"
      },
      "source": [
        "### Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtOhb7kR3AC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0uVoHIQ3DbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO3WCmo2nB-Q",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the raw images "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMONiajb3N-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSpOtG-O3P-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkKcszhEm-KR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H1vHLHUmUId",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7r_aTsV3TMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNCS7L2amtYn",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG2URME73ePz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_original = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av71E0Qcnwon",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY2A6qRw3hee",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_original.history['loss']\n",
        "val_loss = history_original.history['val_loss']\n",
        "acc = history_original.history['accuracy']\n",
        "val_acc = history_original.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjn8ELnOuPoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCMsOomhuYDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/dataset/cats_and_dogs_small.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZly67jTunZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/drive/My Drive/dataset/cats_and_dogs_small.h5')\n",
        "model.summary() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnFtBbBinLgz",
        "colab_type": "text"
      },
      "source": [
        "### Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xC5jis8VvsEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/My Drive/dataset/test_cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VkJ4t1EwB60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csqfQGXA4yRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soNPu-2ZDc5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_dog.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ysz9VFkkDscm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sT7qfljDuov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtPpxGzPstu0",
        "colab_type": "text"
      },
      "source": [
        "## Feature Map Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkj2LW13wPCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Extracts the outputs of the top 8 layers:\n",
        "layer_outputs = [layer.output for layer in model.layers[:8]]\n",
        "\n",
        "# Creates a model that will return these outputs, given the model input:\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI3AjEG8wi3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This will return a list of 5 Numpy arrays:\n",
        "# one array per layer activation\n",
        "activations = activation_model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHuLYMC02C63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_layer_activation = activations[0]\n",
        "print(first_layer_activation.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3bmVbgY3pux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "i = 30 # Try i from 0 to 51\n",
        "plt.matshow(first_layer_activation[0, :, :, i], cmap='viridis')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymKYpQ8455wq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_names = []\n",
        "for layer in model.layers[:8]:\n",
        "    layer_names.append(layer.name)\n",
        "\n",
        "images_per_row = 16\n",
        "\n",
        "for layer_name, layer_activation in zip(layer_names, activations):\n",
        "    # This is the number of features in the feature map\n",
        "    n_features = layer_activation.shape[-1]\n",
        "\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = layer_activation.shape[1]\n",
        "\n",
        "    # We will tile the activation channels in this matrix\n",
        "    n_cols = n_features // images_per_row\n",
        "    display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
        "\n",
        "    # We'll tile each filter into this big horizontal grid\n",
        "    for col in range(n_cols):\n",
        "        for row in range(images_per_row):\n",
        "            channel_image = layer_activation[0,\n",
        "                                             :, :,\n",
        "                                             col * images_per_row + row]\n",
        "            # Post-process the feature to make it visually palatable\n",
        "            channel_image -= channel_image.mean()\n",
        "            channel_image /= channel_image.std()\n",
        "            channel_image *= 64\n",
        "            channel_image += 128\n",
        "            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
        "            display_grid[col * size : (col + 1) * size,\n",
        "                         row * size : (row + 1) * size] = channel_image\n",
        "\n",
        "    # Display the grid\n",
        "    scale = 1. / size\n",
        "    plt.figure(figsize=(scale * display_grid.shape[1],\n",
        "                        scale * display_grid.shape[0]))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98wWam50o8Vx",
        "colab_type": "text"
      },
      "source": [
        "## Multiple Categories Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCNstbNxIvJF",
        "colab_type": "text"
      },
      "source": [
        "### Access the data to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWAewVQRpHUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq3UW9SleU36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IohVMD8VhvsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ls '/content/drive/My Drive/dataset/transport'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLEj-Bzqkl0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/dataset/transport\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwvTrMrjXntA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuAmMj2zXsGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_car_dir = os.path.join(train_dir, 'car')  # directory with our training car pictures\n",
        "train_bike_dir = os.path.join(train_dir, 'bike')  # directory with our training bike pictures\n",
        "train_plane_dir = os.path.join(train_dir, 'plane')  # directory with our training bike pictures\n",
        "validation_car_dir = os.path.join(validation_dir, 'car')  # directory with our validation car pictures\n",
        "validation_bike_dir = os.path.join(validation_dir, 'bike')  # directory with our validation bike pictures\n",
        "validation_plane_dir = os.path.join(validation_dir, 'plane')  # directory with our validation bus pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qygKKy3cYM3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_car_dir)\n",
        "print(train_bike_dir)\n",
        "print(train_plane_dir)\n",
        "print(validation_car_dir)\n",
        "print(validation_bike_dir)\n",
        "print(validation_plane_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeD1zJ7xYnTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_car_tr = len(os.listdir(train_car_dir))\n",
        "num_bike_tr = len(os.listdir(train_bike_dir))\n",
        "num_plane_tr = len(os.listdir(train_plane_dir))\n",
        "\n",
        "num_car_val = len(os.listdir(validation_car_dir))\n",
        "num_bike_val = len(os.listdir(validation_bike_dir))\n",
        "num_plane_val = len(os.listdir(validation_plane_dir))\n",
        "\n",
        "total_train = num_car_tr + num_bike_tr + num_plane_tr\n",
        "total_val = num_car_val + num_bike_val + num_plane_val\n",
        "\n",
        "print('total training car images:', num_car_tr)\n",
        "print('total training bike images:', num_bike_tr)\n",
        "print('total training bus images:', num_plane_tr)\n",
        "\n",
        "print('total validation car images:', num_car_val)\n",
        "print('total validation bike images:', num_bike_val)\n",
        "print('total validation plane images:', num_plane_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iILAEv3tk3wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6lCAA6WI1jV",
        "colab_type": "text"
      },
      "source": [
        "### Image Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKXdFbaOk9Su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "desF72rqlPkB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size, \n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWb25-Yllhg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_training_images, _ = next(train_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snSwkbSApodF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFUe6yDOlrYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotImages(sample_training_images[:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA8gIBVMI4R9",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWL-q-j7lzvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShXj81TYI9cB",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDWSrk_cl4V5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGBJ7yxU_S2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiACGeIkBPSi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/My Drive/dataset/test_car.jpeg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBBJVqBtBV7A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U3MXvQcBhxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYyS5ZZdB4Wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_bike.jpeg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wFiAxPqB7Db",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSnuWeYFB-ot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6-W1s7NC-w6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_plane.jpeg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CXIMijnDBq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhoEevuNDDOx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgViJ2IO1ndb",
        "colab_type": "text"
      },
      "source": [
        "# Topic 2 Methods to Solve Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkEPDE4CrSsf",
        "colab_type": "text"
      },
      "source": [
        "### Weight Regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8cN_q1kEIlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBR-_z35EQK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LhzkXoiEUGh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIh-q73cEb21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_cats_dir)\n",
        "print(train_dogs_dir)\n",
        "print(validation_cats_dir)\n",
        "print(validation_dogs_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EwiQCysEibC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmhSK6nwEnWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWxfddGcErbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_image_generator = ImageDataGenerator(rescale=1./255) \n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvNaLl0aEsa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                           class_mode='categorical')\n",
        "\n",
        "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                              class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIe71UZ6Ex52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZju7TMsFURb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_l2 = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNeqV73JGoTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_l2.history['loss']\n",
        "val_loss = history_l2.history['val_loss']\n",
        "acc = history_l2.history['accuracy']\n",
        "val_acc = history_l2.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2-O3eX-H5SP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l1(0.001), input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', kernel_regularizer=regularizers.l1(0.001), activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Hm9YwqH_LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_l1 = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STgaNNW7IL24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_l1.history['loss']\n",
        "val_loss = history_l1.history['val_loss']\n",
        "acc = history_l1.history['accuracy']\n",
        "val_acc = history_l1.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWaQiuA-Lffs",
        "colab_type": "text"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkPvPWENLwqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJsEedg5MBr8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_dropout = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yrp6D1LuMD7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_dropout.history['loss']\n",
        "val_loss = history_dropout.history['val_loss']\n",
        "acc = history_dropout.history['accuracy']\n",
        "val_acc = history_dropout.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6mpaNGixeDu",
        "colab_type": "text"
      },
      "source": [
        "### Data Augumentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkyUlE-g4KN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBNK6kzB4Nrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMtG5LNYOMO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSY-00oU4SCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRck3uIwyeLo",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QU9CT1u4WYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(2, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6naCWJHxygNk",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWN9-NfR4Z5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history_augmentation = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4eKE0nEyxfk",
        "colab_type": "text"
      },
      "source": [
        "### Evalaute the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTVpfC2X4erj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history_augumentation.history['loss']\n",
        "val_loss = history_augumentation.history['val_loss']\n",
        "acc = history_augumentation.history['accuracy']\n",
        "val_acc = history_augumentation.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPNM818eRSXh",
        "colab_type": "text"
      },
      "source": [
        "### Comparison of Methods "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO9pQyVMRRg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_loss_original = history_original.history['val_loss']\n",
        "val_loss_l1 = history_l1.history['val_loss']\n",
        "val_loss_l2 = history_l2.history['val_loss']\n",
        "val_loss_dropout = history_dropout.history['val_loss']\n",
        "val_loss_augmentation = history_augumentation.history['val_loss']\n",
        "\n",
        "val_acc_original = history_original.history['val_accuacy']\n",
        "val_acc_l1 = history_l1.history['val_accuacy']\n",
        "val_acc_l2 = history_l2.history['val_accuacy']\n",
        "val_acc_dropout = history_dropout.history['val_accuacy']\n",
        "val_acc_augmentation = history_augumentation.history['val_accuacy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss_original,label='Original val_loss')\n",
        "plt.plot(epoch,val_loss_l1,label='L1 Regularization val_loss')\n",
        "plt.plot(epoch,val_loss_l2,label='L2 Regularization val_loss')\n",
        "plt.plot(epoch,val_loss_droput,label='Dropout val_loss')\n",
        "plt.plot(epoch,val_loss_augmentation,label='Data Augmentation val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc_original,label='Original val_acc')\n",
        "plt.plot(epoch,val_acc_l1,label='L1 Regularization val_acc')\n",
        "plt.plot(epoch,val_acc_l2,label='L2 Regularization val_acc')\n",
        "plt.plot(epoch,val_acc_droput,label='Dropout val_acc')\n",
        "plt.plot(epoch,val_acc_augmentation,label='Data Augmentation val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMaVg1zTKCIG",
        "colab_type": "text"
      },
      "source": [
        "## Activity: Dropout and Data Augmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkCujaTvKBAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLW6dO7GLStl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/dataset/transport\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIw08yAA7f5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhwnLCbb7qs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_car_dir = os.path.join(train_dir, 'car')  # directory with our training car pictures\n",
        "train_bike_dir = os.path.join(train_dir, 'bike')  # directory with our training bike pictures\n",
        "train_plane_dir = os.path.join(train_dir, 'plane')  # directory with our training bike pictures\n",
        "validation_car_dir = os.path.join(validation_dir, 'car')  # directory with our validation car pictures\n",
        "validation_bike_dir = os.path.join(validation_dir, 'bike')  # directory with our validation bike pictures\n",
        "validation_plane_dir = os.path.join(validation_dir, 'plane')  # directory with our validation bus pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Vtvavt7xUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_car_tr = len(os.listdir(train_car_dir))\n",
        "num_bike_tr = len(os.listdir(train_bike_dir))\n",
        "num_plane_tr = len(os.listdir(train_plane_dir))\n",
        "\n",
        "num_car_val = len(os.listdir(validation_car_dir))\n",
        "num_bike_val = len(os.listdir(validation_bike_dir))\n",
        "num_plane_val = len(os.listdir(validation_plane_dir))\n",
        "\n",
        "total_train = num_car_tr + num_bike_tr + num_plane_tr\n",
        "total_val = num_car_val + num_bike_val + num_plane_val\n",
        "\n",
        "print('total training car images:', num_car_tr)\n",
        "print('total training bike images:', num_bike_tr)\n",
        "print('total training bus images:', num_plane_tr)\n",
        "\n",
        "print('total validation car images:', num_car_val)\n",
        "print('total validation bike images:', num_bike_val)\n",
        "print('total validation plane images:', num_plane_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrV5JzSk78nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPhfDE1l8ENh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB2-2ZnP8T9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdNXhQ0y8ZAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip( images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyz1GLPZ8g8J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented_images = [train_data_gen[0][0][0] for i in range(5)]\n",
        "plotImages(augmented_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLQc_6Q98mgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, 3, padding='same', activation='relu', input_shape = (IMG_HEIGHT, IMG_WIDTH,3)),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Conv2D(128, 3, padding='same', activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zn9Lctpx8rQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history= model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nOtnEl5-0Y0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HeWq_7zY6oh",
        "colab_type": "text"
      },
      "source": [
        "# Topic 3 Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_aEYm4PVptX",
        "colab_type": "text"
      },
      "source": [
        "## Feature Extraction & Fine Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6b5TlezSh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5oFy8mPzroV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(150, 150, 3)) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(2,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_SuYmC4k6dI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5Uf1n7ul76f",
        "colab_type": "text"
      },
      "source": [
        "### Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eMSbERplvws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# base_model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvxkgU8Jl_5T",
        "colab_type": "text"
      },
      "source": [
        "### Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0G65Lqr0M1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HTmMZdOkijV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtBKV-RAkje1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkYtfpGZkn_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPisPFStku2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_cats_tr = len(os.listdir(train_cats_dir))\n",
        "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
        "\n",
        "num_cats_val = len(os.listdir(validation_cats_dir))\n",
        "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
        "\n",
        "total_train = num_cats_tr + num_dogs_tr\n",
        "total_val = num_cats_val + num_dogs_val\n",
        "\n",
        "print('total training cat images:', num_cats_tr)\n",
        "print('total training dog images:', num_dogs_tr)\n",
        "\n",
        "print('total validation cat images:', num_cats_val)\n",
        "print('total validation dog images:', num_dogs_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdBrPCbT01fP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLg258YE09am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr_nO92c1ZR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmbjR6ar2Fdo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history= model.fit(\n",
        "    train_data_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_data_gen\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JAVJ6-Ym6wk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AliO7-3ZVY0R",
        "colab_type": "text"
      },
      "source": [
        "#### Testing the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f_HxRBW0aGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "img_path = '/content/drive/My Drive/dataset/test_cat.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h26GlSSs6Ima",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtEBS8n76MlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG5RKBIT7isb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = '/content/drive/My Drive/dataset/test_dog.jpg'\n",
        "img = image.load_img(img_path, target_size=(150, 150))\n",
        "img_tensor = image.img_to_array(img)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "img_tensor /= 255.\n",
        "print(img_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raRlK-t66dOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(img_tensor[0])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hGOKuAB6gQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(img_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz3J0aNwurpH",
        "colab_type": "text"
      },
      "source": [
        "## Ex: Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aKz3mPpmRj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnbzU1Czu5Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = \"/content/drive/My Drive/dataset/transport\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbzK7o6bvBKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMnmd1nQvFR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_car_dir = os.path.join(train_dir, 'car')  # directory with our training car pictures\n",
        "train_bike_dir = os.path.join(train_dir, 'bike')  # directory with our training bike pictures\n",
        "train_plane_dir = os.path.join(train_dir, 'plane')  # directory with our training bike pictures\n",
        "validation_car_dir = os.path.join(validation_dir, 'car')  # directory with our validation car pictures\n",
        "validation_bike_dir = os.path.join(validation_dir, 'bike')  # directory with our validation bike pictures\n",
        "validation_plane_dir = os.path.join(validation_dir, 'plane')  # directory with our validation bus pictures"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw30hBYavIvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_car_tr = len(os.listdir(train_car_dir))\n",
        "num_bike_tr = len(os.listdir(train_bike_dir))\n",
        "num_plane_tr = len(os.listdir(train_plane_dir))\n",
        "\n",
        "num_car_val = len(os.listdir(validation_car_dir))\n",
        "num_bike_val = len(os.listdir(validation_bike_dir))\n",
        "num_plane_val = len(os.listdir(validation_plane_dir))\n",
        "\n",
        "total_train = num_car_tr + num_bike_tr + num_plane_tr\n",
        "total_val = num_car_val + num_bike_val + num_plane_val\n",
        "\n",
        "print('total training car images:', num_car_tr)\n",
        "print('total training bike images:', num_bike_tr)\n",
        "print('total training bus images:', num_plane_tr)\n",
        "\n",
        "print('total validation car images:', num_car_val)\n",
        "print('total validation bike images:', num_bike_val)\n",
        "print('total validation plane images:', num_plane_val)\n",
        "print(\"--\")\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gYSJX5NvMc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 10\n",
        "epochs = 15\n",
        "IMG_HEIGHT = 150\n",
        "IMG_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwv5PLNqvQxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_gen_train = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=45,\n",
        "                    width_shift_range=.15,\n",
        "                    height_shift_range=.15,\n",
        "                    horizontal_flip=True,\n",
        "                    zoom_range=0.5\n",
        "                    )\n",
        "image_gen_val = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI68DSXuvRWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n",
        "                                                     directory=train_dir,\n",
        "                                                     shuffle=True,\n",
        "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                     class_mode='categorical')\n",
        "\n",
        "val_data_gen = image_gen_val.flow_from_directory(batch_size=batch_size,\n",
        "                                                 directory=validation_dir,\n",
        "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "                                                 class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mq6_PpsvvhcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow. keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4aDUH0kvoZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model=MobileNet(weights='imagenet',include_top=False, input_shape=(150, 150, 3)) \n",
        "\n",
        "x=base_model.output\n",
        "x=GlobalAveragePooling2D()(x)\n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(1024,activation='relu')(x) \n",
        "x=Dense(512,activation='relu')(x) \n",
        "preds=Dense(3,activation='softmax')(x) \n",
        "\n",
        "model=Model(inputs=base_model.input,outputs=preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQ00Y_cvsjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers[:20]:\n",
        "    layer.trainable=False\n",
        "for layer in model.layers[20:]:\n",
        "    layer.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp9rtyVNv3hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_data_gen,epochs=epochs,validation_data=val_data_gen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_jwxSBk2XaO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epoch = range(len(loss))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epoch,loss,label='loss')\n",
        "plt.plot(epoch,val_loss,label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epoch,acc,label='acc')\n",
        "plt.plot(epoch,val_acc,label='val_acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}